# Sample Data Files

This directory contains sample data files for testing datui. All files are generated by the script in `scripts/generate_sample_data.py`.

## File Descriptions

### People Data (Grouping Tests)
- **people.csv** / **people.parquet**: 1000 rows of people data with cities, states, departments, etc.
  - Ideal for testing grouping operations
  - Contains columns: id, first_name, last_name, age, city, state, department, job_title, salary, start_date, active
  - Includes ~10% null values in city, department, and salary columns
  - Good for testing: `select * by city, state` or `select avg(salary) by department`

### Sales Data (Aggregate Tests)
- **sales.csv** / **sales.parquet**: 5000 rows of sales transactions
  - Ideal for testing aggregate calculations (sum, avg, count, etc.)
  - Contains columns: date, product, region, quantity, unit_price, discount, total
  - Includes ~5% null values
  - Good for testing: `select sum(total), avg(quantity) by product, region`

### Mixed Types
- **mixed_types.csv** / **mixed_types.parquet**: 200 rows with various data types
  - Tests handling of different data types: integers, floats, strings, booleans, dates
  - Contains ~15% null values across all columns
  - Good for testing type handling and null value display

### Quoted Strings
- **quoted_strings.csv**: CSV with all strings quoted (QUOTE_ALL)
  - Contains strings with commas, newlines, and quotes
  - Tests CSV parsing with complex string escaping

- **unquoted_strings.csv**: CSV with only non-numeric strings quoted (QUOTE_NONNUMERIC)
  - Similar content but different quoting style
  - Tests CSV parsing with different quoting strategies

### Edge Cases
- **empty.csv** / **empty.parquet**: Empty table with schema only
  - Tests handling of empty datasets
  - Columns: id, name, value, date

- **single_row.csv** / **single_row.parquet**: Table with exactly one row
  - Tests edge case of minimal data
  - Good for testing UI with very small datasets

### Large Dataset
- **large_dataset.csv** / **large_dataset.parquet**: 100,000 rows
  - Tests performance with large datasets
  - Contains: id, category, value1, value2, value3, timestamp
  - Good for testing scrolling, filtering, and performance

### Error Cases
- **error_inconsistent_types.csv**: Column with mixed types (numbers and strings)
  - Tests error handling when types are inconsistent
  - Note: Cannot be saved as Parquet (Parquet requires consistent types)

- **error_long_strings.csv** / **error_long_strings.parquet**: Very long string values
  - Each string is 1000 characters
  - Tests UI handling of long text values

- **error_special_chars.csv** / **error_special_chars.parquet**: Special characters and Unicode
  - Contains null bytes, tabs, newlines, carriage returns, backslashes
  - Contains Unicode characters (Greek, emoji, Chinese, Arabic, Russian)
  - Tests handling of edge case characters

## Regenerating Data

To regenerate all sample data files:

```bash
# Activate virtual environment (if using one)
source .venv/bin/activate

# Install dependencies (if needed)
pip install -r scripts/requirements.txt

# Run the generation script
python scripts/generate_sample_data.py
```

The script uses seeded random number generators, so the data will be consistent across runs.

## Usage Examples

### Grouping Examples
```sql
-- Group people by city and state
select * by city, state

-- Aggregate salaries by department
select avg(salary), count(*) by department

-- Group by state and show city counts
select count(city) by state
```

### Aggregate Examples
```sql
-- Total sales by product
select sum(total), avg(quantity) by product

-- Sales by region and month
select sum(total), count(*) by region
```

### Filtering Examples
```sql
-- Filter people in specific state
select * where state = 'CA'

-- Filter sales above threshold
select * where total > 1000
```
